TODO #3 - DONE
target: ScraperService.scrape_appartments_count_for_city()
break smth so that it breaks the whole process
and then wrap with try except and try to save the whole process from crashing
and log the failed city and add it to the leftovers_list
iterate over the leftovers and run scrape_appartments_count_for_city()


TODO #4 DONE
1) log exceptions to a local file
2) log exceptions to a some remote storage (maybe later)


TODO #5 DONE
Refactoring in DataBaseService
DRY

TODO #5
Implement DataProcessor DONE
Apply DataProcessor in the middle of ScraperService and DataBaseService
It's not ScraperService's responsibility to persist the scraped data. Its
responsibility is to do the scraping and return the results.

TODO #7 DONE
python linter on precommit hook
PEP 8


TODO #9
Tests. Unittests with pytest


TODO #2

1. try multithreaded appraoch: each city in a separate thread
2. then try multiple servers approach. Each server is responsible of its own city. Each server has its unique IP address


TODO #8
Run the app as a web server. The server runs locally. All error/exceptions
are handled and loged. Test coverage is ~80%. Tests are run on precommit hook.

The app 1.0 is ready to be deployed.

===============================================================================
CHECKPOINT
===============================================================================

TODO #6
deploy

TODO #1

CI/CD Integration:

If possible, integrate your database schema changes into your Continuous
Integration / Continuous Deployment (CI/CD) pipeline. This ensures that your
database changes are automatically applied when deploying your application.



CRITICAL LEFTOVERS:
- testing and test coverage
- CI/CD pipline
- deploy and launch
- minimal website:
    - LOGIN/LOGOUT
    - AUTH and premissions management
    - more SQL selects/joins/views
    - visual representation of scraped data
